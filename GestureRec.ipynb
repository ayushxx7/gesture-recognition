{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8501d451-dc8b-4c23-a35e-cc3f30597e22",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "#### Submitted by\n",
    "- Sameer Soin\n",
    "- Ayush Mandowara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32d191-d78e-4887-a229-74faab90e16c",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "A smart tv manufactures wants to add gesture based controls to their TVs. \n",
    "\n",
    "To start with, the following 5 gestures are planned to be undstood by the TV:\n",
    "- Thumbs Up to increase volume\n",
    "- Thumbs Down to decrease volume\n",
    "- Left Swipe to move 10 seconds back\n",
    "- Right Swipe to move 10 seconds ahead\n",
    "- Open Palm (Stop) to pause\n",
    "\n",
    "The hardware and software to capture and take action based on the gestures already exists with the manufacturer, our focus will be on `Recognising the Gestures`.\n",
    "\n",
    "## Data\n",
    "- The data we have been provided with to train our model consists of images / frames taken in a sequence (videos that are already broken down into images) for various individuals showing the above mentioned hand gestures.  \n",
    "- The data is labelled with the different classes (gestures) that need to be identified.\n",
    "\n",
    "## Approach\n",
    "To do this, we will be using `Deep Learning`. Specifically, we will be trying two approaches:\n",
    "- Approach 1: 3D CNN Model  \n",
    "- Approach 2: A CNN + RNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9d080-e0a1-43bc-be69-e858bb318df4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74efc6-768b-46a6-8b07-98b3bbb73c3a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6104d6b9-88c0-43bc-a0eb-d7db3901e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from cv2 import imread\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e2c6fc7-5a9c-466f-a127-c08fde435941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logger to enable / disable debug statements quickly.\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee410348-4271-4d4d-b6cb-25adb6d66729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6007806666564665693\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06307e-66c5-4906-839d-6a1e8e44784a",
   "metadata": {},
   "source": [
    "### Fixed Random Seeds\n",
    "- This helps in reproducing results in subsequent runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2d80c5-8590-47a1-9659-ec33bea6ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rn.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d26de4-1c9e-4df4-a51b-80ce327558b1",
   "metadata": {},
   "source": [
    "## Reading the Data\n",
    "- The data is labelled\n",
    "- The file paths along with labels are stored in csv files\n",
    "- Data is already divided into train and validation folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1662ff-fe92-4973-a9ba-c98dd2aa900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "project_root = \"Project_data\"\n",
    "train_folder = os.path.join(project_root, \"train\")\n",
    "val_folder = os.path.join(project_root, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2da953-fe99-4942-b9be-7a39dea51448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WIN_20180925_18_23_57_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f05df33-4202-4cc0-bc21-2d3e43db2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cc546f-60f4-470b-8050-f2c31b037a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Project_data/train.csv', delimiter=';', names=['Video Folder', 'Gesture', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb688e1-2fc9-4f5b-817a-5dd5eba6d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fef53e4-2b20-4a65-af28-e897f07e611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_08_43_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_17_18_28_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_17_18_56_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder         Gesture  Label\n",
       "0  WIN_20180925_17_08_43_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "1  WIN_20180925_17_18_28_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "2  WIN_20180925_17_18_56_Pro_Left_Swipe_new  Left_Swipe_new      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44583bb5-40d5-4d3b-8a6b-47803f28454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>WIN_20180907_16_42_05_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>WIN_20180907_16_42_55_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>WIN_20180907_16_43_39_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Video Folder        Gesture  Label\n",
       "660  WIN_20180907_16_42_05_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "661  WIN_20180907_16_42_55_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "662  WIN_20180907_16_43_39_Pro_Thumbs Up_new  Thumbs Up_new      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2c8c4b-3b94-4d49-a721-82a66887710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('Project_data/val.csv', delimiter=';', names=['Video Folder', 'Gesture', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04e3858-534c-4f87-b66c-8d5d21ec22af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_17_04_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_17_43_01_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_18_01_40_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder         Gesture  Label\n",
       "0  WIN_20180925_17_17_04_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "1  WIN_20180925_17_43_01_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "2  WIN_20180925_18_01_40_Pro_Left_Swipe_new  Left_Swipe_new      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea09955c-7a39-4072-a1d5-75f8027ed626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WIN_20180907_15_54_30_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WIN_20180907_16_10_59_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>WIN_20180907_16_39_59_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder        Gesture  Label\n",
       "97  WIN_20180907_15_54_30_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "98  WIN_20180907_16_10_59_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "99  WIN_20180907_16_39_59_Pro_Thumbs Up_new  Thumbs Up_new      4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fbe3912-7078-434a-833c-8a9b8065d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = shuffle(train_df, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db505c0-4376-474c-8b55-619f255ac03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>WIN_20180907_16_21_11_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...</td>\n",
       "      <td>Left Swipe_new_Left Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>WIN_20180926_17_23_38_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WIN_20180926_17_21_49_Pro_Stop_new</td>\n",
       "      <td>Stop_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video Folder  \\\n",
       "327          WIN_20180925_18_23_57_Pro_Thumbs_Down_new   \n",
       "579         WIN_20180907_16_21_11_Pro_Stop Gesture_new   \n",
       "513  WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...   \n",
       "362          WIN_20180926_17_23_38_Pro_Thumbs_Down_new   \n",
       "265                 WIN_20180926_17_21_49_Pro_Stop_new   \n",
       "\n",
       "                           Gesture  Label  \n",
       "327                Thumbs_Down_new      3  \n",
       "579               Stop Gesture_new      2  \n",
       "513  Left Swipe_new_Left Swipe_new      0  \n",
       "362                Thumbs_Down_new      3  \n",
       "265                       Stop_new      2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f87d5a34-36ad-4751-ab50-a35922673887",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = shuffle(val_df, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f6b314-6459-444a-936d-5cffc80184b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>WIN_20180907_16_30_54_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WIN_20180925_17_38_43_Pro_Thumbs_Up_new</td>\n",
       "      <td>Thumbs_Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WIN_20180907_15_55_06_Pro_Right Swipe_new</td>\n",
       "      <td>Right Swipe_new</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>WIN_20180926_16_57_50_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WIN_20180926_16_44_04_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Video Folder           Gesture  Label\n",
       "83  WIN_20180907_16_30_54_Pro_Stop Gesture_new  Stop Gesture_new      2\n",
       "53     WIN_20180925_17_38_43_Pro_Thumbs_Up_new     Thumbs_Up_new      4\n",
       "70   WIN_20180907_15_55_06_Pro_Right Swipe_new   Right Swipe_new      1\n",
       "45   WIN_20180926_16_57_50_Pro_Thumbs_Down_new   Thumbs_Down_new      3\n",
       "44   WIN_20180926_16_44_04_Pro_Thumbs_Down_new   Thumbs_Down_new      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "721495ec-8b63-4acf-acf8-71a5ff8b75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd83d3b-d80f-4641-9171-d8dd3e9cb51c",
   "metadata": {},
   "source": [
    "### Display a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f2a7297-64f7-49a9-ba4f-38d83b0531b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Video Folder          Gesture  Label\n",
       "0  WIN_20180925_18_23_57_Pro_Thumbs_Down_new  Thumbs_Down_new      3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45065491-d7b8-4191-9dea-765806996af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path_train(idx):\n",
    "    video_name = train_df.iloc[idx]['Video Folder']\n",
    "    video_path = os.path.join(train_folder, video_name)\n",
    "    return video_path\n",
    "\n",
    "def get_image_list_train(idx):\n",
    "    ims = os.listdir(get_video_path_train(idx))\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "598d37dc-19a4-4b7f-911c-c55170673769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project_data\\\\train\\\\WIN_20180925_18_23_57_Pro_Thumbs_Down_new'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_path_train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50fab01a-a6dd-4089-9e1f-cbfe9aee5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = get_image_list_train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cb598c5-c3a3-4b68-bd51-17bf47dd6797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b17a32c-b3b4-4d3f-bdd5-5c335374b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence(train_idx, rows=3, columns=10, fig_size=(20,3), step_size=1):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ims = get_image_list_train(train_idx)\n",
    "    folder_path = get_video_path_train(train_idx)\n",
    "    \n",
    "    for i in range(1, columns*rows+1, step_size):\n",
    "        img = imread(os.path.join(folder_path, ims[i-1]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5d72896-c8ba-46d8-82b1-7154a1d2e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe82e48-3e80-4638-b3c3-96e89859d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a0cd7-3dc2-49f6-932f-48c40b8c252d",
   "metadata": {},
   "source": [
    "### Checking GPU Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ab79d6a-733a-46a9-b977-39af3cd47006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d706515-a8af-4df0-b0b9-b599204d42a9",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "### Problems\n",
    "- Since the data is huge, it cannot be processed in a single go. The machine will throw out of memory error.\n",
    "- There are images in two types (dimension 120x120 and 360x), we need to make the dimensions same\n",
    "- There is some room for skipping images to speed up the training process\n",
    "- Data augmentation may be required to increase accuracy\n",
    "- Ablation will be required to reduce analysis time\n",
    "\n",
    "### Solution\n",
    "All of the above can be achieved with the help of a custom generator which generates data in batches as per requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7668b6d0-d43c-49f2-8bc0-8bef9c0b04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProps:\n",
    "    \"\"\"Image class to easily store, retrieve and update properties of input images during training\"\"\"\n",
    "    img_selection_via_idx = [3, 6, 9, 12, 15, 18, 21]\n",
    "    img_selection_len = len(img_selection_via_idx)\n",
    "    \n",
    "    img_resize_height = 100\n",
    "    img_resize_width = 100\n",
    "    \n",
    "    img_crop_width_lower_limit = 10\n",
    "    img_crop_width_upper_limit = 90\n",
    "    img_crop_height_lower_limit = 10\n",
    "    img_crop_height_upper_limit = 90\n",
    "    \n",
    "    img_height = 80\n",
    "    img_width = 80\n",
    "    \n",
    "    def normalize_channel(self, input_channel, lower_percentile=5, upper_percentile=95):\n",
    "        \"\"\"To normalize input channel using percentile values\"\"\"\n",
    "        lower_percentile_val = np.percentile(input_channel, lower_percentile)\n",
    "        upper_percentile_val = np.percentile(input_channel, upper_percentile)\n",
    "        \n",
    "        numerator = input_channel-lower_percentile_val\n",
    "        denominator = upper_percentile_val-lower_percentile_val\n",
    "        \n",
    "        normalized_channel = numerator/denominator\n",
    "        \n",
    "        return normalized_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f463d38-35df-4276-b540-ebef9ab99bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_props = ImageProps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00bce96b-0115-41fb-b814-a6ca564d6b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9, 12, 15, 18, 21]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_props.img_selection_via_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b5365ef4-b568-44c0-ae66-b9548f12cc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoBatchGenerator:\n",
    "    \"\"\"Generator class to generate images in batches as per requirement\n",
    "    \n",
    "    Number of channels in RGB image is 3\n",
    "    Number of gestures / output classes is 5\n",
    "    \n",
    "    Batch Data dimensions:\n",
    "    - images have 2 dimensions (width x height)\n",
    "    - rgb images have 3 channels (width x height x 3)\n",
    "    - videos are sequence of rgb images (sequence of images x width x height x 3)\n",
    "    - each batch has prespecified number of videos (batch size * sequence of images * width * height * 3)\n",
    "    \"\"\"\n",
    "    batch_size = 3\n",
    "    num_images_per_video = img_props.img_selection_len\n",
    "    img_height = img_props.img_height\n",
    "    img_width = img_props.img_width\n",
    "    NUM_RGB_CHANNELS = 3\n",
    "    NUM_CLASSES = 5\n",
    "    \n",
    "    def batch_generator(self, parent_folder_path, df):\n",
    "        num_videos = len(df)\n",
    "        # batch size cannot be larger than the input video sequence\n",
    "        self.batch_size = min(self.batch_size, num_videos)\n",
    "        num_batches = num_videos//self.batch_size\n",
    "        extra_batch_size = num_videos%self.batch_size\n",
    "        \n",
    "        log.info(f\"Source Path: {parent_folder_path}\")\n",
    "        log.info(f\"Number of Videos: {num_videos}\")\n",
    "        log.info(f\"Batch Size: {self.batch_size}\") \n",
    "        log.info(f\"Number of Batches: {num_batches}\")\n",
    "        log.info(f\"Extra Batch Size (zero means no extra batch): {extra_batch_size}\")\n",
    "        \n",
    "        while True:\n",
    "            shuffled_df = shuffle(df, random_state=RANDOM_SEED)\n",
    "            shuffled_video_folders = shuffled_df['Video Folder']\n",
    "            shuffled_labels = shuffled_df['Label']\n",
    "            \n",
    "            logging.debug(f\"{shuffled_df.head()}\")\n",
    "            \n",
    "            for batch_id in range(num_batches):\n",
    "                log.info(f\"Current Batch: {batch_id}\")\n",
    "                batch_data = np.zeros((self.batch_size, \n",
    "                                       self.num_images_per_video, \n",
    "                                       self.img_width, self.img_height, \n",
    "                                       self.NUM_RGB_CHANNELS))\n",
    "                batch_labels = np.zeros((self.batch_size, \n",
    "                                         self.NUM_CLASSES))\n",
    "                \n",
    "                for video_id in range(self.batch_size):\n",
    "                    video_folder_id = video_id + batch_id*self.batch_size\n",
    "                    video_folder_path = os.path.join(parent_folder_path, shuffled_video_folders[video_folder_id])\n",
    "                    logging.debug(f'id: {video_folder_id} video_folder_path: {video_folder_path}')\n",
    "                    imgs_in_video = os.listdir(video_folder_path)\n",
    "                    logging.debug(f'first image: {imgs_in_video[0]}')\n",
    "                    \n",
    "                    for img_id, img_id_in_video in enumerate(img_props.img_selection_via_idx):\n",
    "                        img = imgs_in_video[img_id_in_video]\n",
    "                        logging.debug(f'current image via selection: {img}')\n",
    "                        img_path = os.path.join(video_folder_path, img)\n",
    "                        logging.debug(f'current image via selection [path]: {img_path}')\n",
    "                        img_array = imread(img_path)\n",
    "                        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        #plt.imshow(img_array)\n",
    "                        #plt.show()\n",
    "                        \n",
    "                        resized_image = cv2.resize(img_array, (\n",
    "                                        img_props.img_resize_width, \n",
    "                                        img_props.img_resize_height,\n",
    "                                        ))\n",
    "                        \n",
    "                        cropped_image = resized_image = resized_image[\n",
    "                            img_props.img_crop_width_lower_limit:img_props.img_crop_width_upper_limit,\n",
    "                            img_props.img_crop_height_lower_limit:img_props.img_crop_height_upper_limit,\n",
    "                        ]\n",
    "                        \n",
    "                        logging.debug(f\"Shape of cropped image (after resize): {cropped_image.shape}\")\n",
    "                        \n",
    "                        red_channel = cropped_image[:, :, 0]\n",
    "                        green_channel = cropped_image[:, :, 1]\n",
    "                        blue_channel = cropped_image[:, :, 2]\n",
    "                        \n",
    "                        batch_data[video_id, img_id, :, :, 0] = img_props.normalize_channel(red_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 1] = img_props.normalize_channel(green_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 2] = img_props.normalize_channel(blue_channel)\n",
    "                        \n",
    "                    batch_labels[video_id, shuffled_labels[video_folder_id]] = 1\n",
    "                    logging.debug(f\"batch data: for video:img [{video_id}:{img_id}] = {batch_data[video_id, img_id, :, :, 0]}\")\n",
    "                    logging.debug(f\"batch label: {video_id} = {batch_labels[video_id]}\")\n",
    "                yield batch_data, batch_labels\n",
    "            \n",
    "            if extra_batch_size:\n",
    "                last_batch_id = batch_id + 1\n",
    "                log.info(f\"Current Batch (Extra Batch): {last_batch_id}\")\n",
    "                batch_data = np.zeros((extra_batch_size, \n",
    "                                       self.num_images_per_video, \n",
    "                                       self.img_width, self.img_height, \n",
    "                                       self.NUM_RGB_CHANNELS))\n",
    "                batch_labels = np.zeros((extra_batch_size, \n",
    "                                         self.NUM_CLASSES))\n",
    "                \n",
    "                for video_id in range(extra_batch_size):\n",
    "                    video_folder_id = video_id + last_batch_id*extra_batch_size\n",
    "                    video_folder_path = os.path.join(parent_folder_path, shuffled_video_folders[video_folder_id])\n",
    "                    logging.debug(f'id: {video_folder_id} video_folder_path: {video_folder_path}')\n",
    "                    imgs_in_video = os.listdir(video_folder_path)\n",
    "                    logging.debug(f'first image: {imgs_in_video[0]}')\n",
    "                    \n",
    "                    for img_id, img_id_in_video in enumerate(img_props.img_selection_via_idx):\n",
    "                        img = imgs_in_video[img_id_in_video]\n",
    "                        logging.debug(f'current image via selection: {img}')\n",
    "                        img_path = os.path.join(video_folder_path, img)\n",
    "                        logging.debug(f'current image via selection [path]: {img_path}')\n",
    "                        img_array = imread(img_path)\n",
    "                        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        #plt.imshow(img_array)\n",
    "                        #plt.show()\n",
    "                        \n",
    "                        resized_image = cv2.resize(img_array, (\n",
    "                                        img_props.img_resize_width, \n",
    "                                        img_props.img_resize_height,\n",
    "                                        ))\n",
    "                        \n",
    "                        cropped_image = resized_image = resized_image[\n",
    "                            img_props.img_crop_width_lower_limit:img_props.img_crop_width_upper_limit,\n",
    "                            img_props.img_crop_height_lower_limit:img_props.img_crop_height_upper_limit,\n",
    "                        ]\n",
    "                        \n",
    "                        logging.debug(f\"Shape of cropped image (after resize): {cropped_image.shape}\")\n",
    "                        \n",
    "                        red_channel = cropped_image[:, :, 0]\n",
    "                        green_channel = cropped_image[:, :, 1]\n",
    "                        blue_channel = cropped_image[:, :, 2]\n",
    "                        \n",
    "                        batch_data[video_id, img_id, :, :, 0] = img_props.normalize_channel(red_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 1] = img_props.normalize_channel(green_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 2] = img_props.normalize_channel(blue_channel)\n",
    "                        \n",
    "                    batch_labels[video_id, shuffled_labels[video_folder_id]] = 1\n",
    "                    logging.debug(f\"batch data: for video:img [{video_id}:{img_id}] = {batch_data[video_id, img_id, :, :, 0]}\")\n",
    "                    logging.debug(f\"batch label: {video_id} = {batch_labels[video_id]}\")\n",
    "                yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "81d1b162-8eb9-4150-9455-9628504309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VideoBatchGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c165efe9-f062-4a48-a995-9480df004e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = v.batch_generator(train_folder, train_df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4a0cef85-a3c7-41e5-a28f-f1088ae6a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Batch: 0\n"
     ]
    }
   ],
   "source": [
    "d = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cea8c681-0293-48b5-a9ce-75a6c9350c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180907_16_21_11_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Video Folder           Gesture  Label\n",
       "0   WIN_20180925_18_23_57_Pro_Thumbs_Down_new   Thumbs_Down_new      3\n",
       "1  WIN_20180907_16_21_11_Pro_Stop Gesture_new  Stop Gesture_new      2"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0a9d6d7d-60cd-4061-9de0-b7fe80f59657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180907_16_21_11_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...</td>\n",
       "      <td>Left Swipe_new_Left Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WIN_20180926_17_23_38_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Video Folder  \\\n",
       "0          WIN_20180925_18_23_57_Pro_Thumbs_Down_new   \n",
       "1         WIN_20180907_16_21_11_Pro_Stop Gesture_new   \n",
       "2  WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...   \n",
       "3          WIN_20180926_17_23_38_Pro_Thumbs_Down_new   \n",
       "\n",
       "                         Gesture  Label  \n",
       "0                Thumbs_Down_new      3  \n",
       "1               Stop Gesture_new      2  \n",
       "2  Left Swipe_new_Left Swipe_new      0  \n",
       "3                Thumbs_Down_new      3  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "642b6799-c5e1-44f3-909a-7f721a495279",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "33dc17af-e235-4f60-bdaa-f363a0fc5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = v.batch_generator(train_folder, train_df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d9d5e03-efec-4d1f-894d-0b7aa11cd767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path: Project_data\\train\n",
      "Number of Videos: 10\n",
      "Batch Size: 3\n",
      "Number of Batches: 3\n",
      "Extra Batch Size (zero means no extra batch): 1\n",
      "Current Batch: 0\n"
     ]
    }
   ],
   "source": [
    "data = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c8b75fde-2669-4c40-a1a0-e51c66560d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Batch (Extra Batch): 3\n"
     ]
    }
   ],
   "source": [
    "data = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "66c60da1-6c4f-4809-94d9-dafdc9542cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38064c9-03a4-4c1a-89e0-21c992b04128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(v.img_array[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928c003-f1ab-4b72-a892-37cbe18ede01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
