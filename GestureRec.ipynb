{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8501d451-dc8b-4c23-a35e-cc3f30597e22",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "#### Submitted by\n",
    "- Sameer Soin\n",
    "- Ayush Mandowara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32d191-d78e-4887-a229-74faab90e16c",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "A smart tv manufactures wants to add gesture based controls to their TVs. \n",
    "\n",
    "To start with, the following 5 gestures are planned to be undstood by the TV:\n",
    "- Thumbs Up to increase volume\n",
    "- Thumbs Down to decrease volume\n",
    "- Left Swipe to move 10 seconds back\n",
    "- Right Swipe to move 10 seconds ahead\n",
    "- Open Palm (Stop) to pause\n",
    "\n",
    "The hardware and software to capture and take action based on the gestures already exists with the manufacturer, our focus will be on `Recognising the Gestures`.\n",
    "\n",
    "## Data\n",
    "- The data we have been provided with to train our model consists of images / frames taken in a sequence (videos that are already broken down into images) for various individuals showing the above mentioned hand gestures.  \n",
    "- The data is labelled with the different classes (gestures) that need to be identified.\n",
    "\n",
    "## Approach\n",
    "To do this, we will be using `Deep Learning`. Specifically, we will be trying two approaches:\n",
    "- Approach 1: 3D CNN Model  \n",
    "- Approach 2: A CNN + RNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9d080-e0a1-43bc-be69-e858bb318df4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74efc6-768b-46a6-8b07-98b3bbb73c3a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6104d6b9-88c0-43bc-a0eb-d7db3901e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from cv2 import imread\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e2c6fc7-5a9c-466f-a127-c08fde435941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logger to enable / disable debug statements quickly.\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "from importlib import reload\n",
    "reload(logging)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, format='',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3e86f6-a883-4000-87d6-69e295ed16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling GPU usage as GPU memory is too low on local machine\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06307e-66c5-4906-839d-6a1e8e44784a",
   "metadata": {},
   "source": [
    "### Fixed Random Seeds\n",
    "- This helps in reproducing results in subsequent runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2d80c5-8590-47a1-9659-ec33bea6ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rn.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d26de4-1c9e-4df4-a51b-80ce327558b1",
   "metadata": {},
   "source": [
    "## Reading the Data\n",
    "- The data is labelled\n",
    "- The file paths along with labels are stored in csv files\n",
    "- Data is already divided into train and validation folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1662ff-fe92-4973-a9ba-c98dd2aa900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "\n",
    "project_root = \"Project_data\"\n",
    "train_folder = os.path.join(project_root, \"train\")\n",
    "val_folder = os.path.join(project_root, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2da953-fe99-4942-b9be-7a39dea51448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WIN_20180925_18_23_57_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f05df33-4202-4cc0-bc21-2d3e43db2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cc546f-60f4-470b-8050-f2c31b037a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Project_data/train.csv', delimiter=';', names=['Video Folder', 'Gesture', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb688e1-2fc9-4f5b-817a-5dd5eba6d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fef53e4-2b20-4a65-af28-e897f07e611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_08_43_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_17_18_28_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_17_18_56_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder         Gesture  Label\n",
       "0  WIN_20180925_17_08_43_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "1  WIN_20180925_17_18_28_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "2  WIN_20180925_17_18_56_Pro_Left_Swipe_new  Left_Swipe_new      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44583bb5-40d5-4d3b-8a6b-47803f28454d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>WIN_20180907_16_42_05_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>WIN_20180907_16_42_55_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>WIN_20180907_16_43_39_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Video Folder        Gesture  Label\n",
       "660  WIN_20180907_16_42_05_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "661  WIN_20180907_16_42_55_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "662  WIN_20180907_16_43_39_Pro_Thumbs Up_new  Thumbs Up_new      4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2c8c4b-3b94-4d49-a721-82a66887710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('Project_data/val.csv', delimiter=';', names=['Video Folder', 'Gesture', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04e3858-534c-4f87-b66c-8d5d21ec22af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_17_17_04_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20180925_17_43_01_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20180925_18_01_40_Pro_Left_Swipe_new</td>\n",
       "      <td>Left_Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder         Gesture  Label\n",
       "0  WIN_20180925_17_17_04_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "1  WIN_20180925_17_43_01_Pro_Left_Swipe_new  Left_Swipe_new      0\n",
       "2  WIN_20180925_18_01_40_Pro_Left_Swipe_new  Left_Swipe_new      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea09955c-7a39-4072-a1d5-75f8027ed626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WIN_20180907_15_54_30_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WIN_20180907_16_10_59_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>WIN_20180907_16_39_59_Pro_Thumbs Up_new</td>\n",
       "      <td>Thumbs Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Video Folder        Gesture  Label\n",
       "97  WIN_20180907_15_54_30_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "98  WIN_20180907_16_10_59_Pro_Thumbs Up_new  Thumbs Up_new      4\n",
       "99  WIN_20180907_16_39_59_Pro_Thumbs Up_new  Thumbs Up_new      4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fbe3912-7078-434a-833c-8a9b8065d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = shuffle(train_df, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db505c0-4376-474c-8b55-619f255ac03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>WIN_20180907_16_21_11_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...</td>\n",
       "      <td>Left Swipe_new_Left Swipe_new</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>WIN_20180926_17_23_38_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WIN_20180926_17_21_49_Pro_Stop_new</td>\n",
       "      <td>Stop_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video Folder  \\\n",
       "327          WIN_20180925_18_23_57_Pro_Thumbs_Down_new   \n",
       "579         WIN_20180907_16_21_11_Pro_Stop Gesture_new   \n",
       "513  WIN_20180907_16_38_29_Pro_Left Swipe_new_Left ...   \n",
       "362          WIN_20180926_17_23_38_Pro_Thumbs_Down_new   \n",
       "265                 WIN_20180926_17_21_49_Pro_Stop_new   \n",
       "\n",
       "                           Gesture  Label  \n",
       "327                Thumbs_Down_new      3  \n",
       "579               Stop Gesture_new      2  \n",
       "513  Left Swipe_new_Left Swipe_new      0  \n",
       "362                Thumbs_Down_new      3  \n",
       "265                       Stop_new      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87d5a34-36ad-4751-ab50-a35922673887",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = shuffle(val_df, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f6b314-6459-444a-936d-5cffc80184b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>WIN_20180907_16_30_54_Pro_Stop Gesture_new</td>\n",
       "      <td>Stop Gesture_new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WIN_20180925_17_38_43_Pro_Thumbs_Up_new</td>\n",
       "      <td>Thumbs_Up_new</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WIN_20180907_15_55_06_Pro_Right Swipe_new</td>\n",
       "      <td>Right Swipe_new</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>WIN_20180926_16_57_50_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WIN_20180926_16_44_04_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Video Folder           Gesture  Label\n",
       "83  WIN_20180907_16_30_54_Pro_Stop Gesture_new  Stop Gesture_new      2\n",
       "53     WIN_20180925_17_38_43_Pro_Thumbs_Up_new     Thumbs_Up_new      4\n",
       "70   WIN_20180907_15_55_06_Pro_Right Swipe_new   Right Swipe_new      1\n",
       "45   WIN_20180926_16_57_50_Pro_Thumbs_Down_new   Thumbs_Down_new      3\n",
       "44   WIN_20180926_16_44_04_Pro_Thumbs_Down_new   Thumbs_Down_new      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721495ec-8b63-4acf-acf8-71a5ff8b75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd83d3b-d80f-4641-9171-d8dd3e9cb51c",
   "metadata": {},
   "source": [
    "### Display a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f2a7297-64f7-49a9-ba4f-38d83b0531b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Folder</th>\n",
       "      <th>Gesture</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20180925_18_23_57_Pro_Thumbs_Down_new</td>\n",
       "      <td>Thumbs_Down_new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Video Folder          Gesture  Label\n",
       "0  WIN_20180925_18_23_57_Pro_Thumbs_Down_new  Thumbs_Down_new      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45065491-d7b8-4191-9dea-765806996af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_path_train(idx):\n",
    "    video_name = train_df.iloc[idx]['Video Folder']\n",
    "    video_path = os.path.join(train_folder, video_name)\n",
    "    return video_path\n",
    "\n",
    "def get_image_list_train(idx):\n",
    "    ims = os.listdir(get_video_path_train(idx))\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598d37dc-19a4-4b7f-911c-c55170673769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project_data\\\\train\\\\WIN_20180925_18_23_57_Pro_Thumbs_Down_new'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_path_train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50fab01a-a6dd-4089-9e1f-cbfe9aee5dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = get_image_list_train(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cb598c5-c3a3-4b68-bd51-17bf47dd6797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b17a32c-b3b4-4d3f-bdd5-5c335374b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence(train_idx, rows=3, columns=10, fig_size=(20,3), step_size=1):\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    ims = get_image_list_train(train_idx)\n",
    "    folder_path = get_video_path_train(train_idx)\n",
    "    \n",
    "    for i in range(1, columns*rows+1, step_size):\n",
    "        img = imread(os.path.join(folder_path, ims[i-1]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5d72896-c8ba-46d8-82b1-7154a1d2e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe82e48-3e80-4638-b3c3-96e89859d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_sequence(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a0cd7-3dc2-49f6-932f-48c40b8c252d",
   "metadata": {},
   "source": [
    "### Checking GPU Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb4f702-f5de-403c-bb9e-953e53c694f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ab79d6a-733a-46a9-b977-39af3cd47006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d706515-a8af-4df0-b0b9-b599204d42a9",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "### Problems\n",
    "- Since the data is huge, it cannot be processed in a single go. The machine will throw out of memory error.\n",
    "- There are images in two types (dimension 120x120 and 360x), we need to make the dimensions same\n",
    "- There is some room for skipping images to speed up the training process\n",
    "- Data augmentation may be required to increase accuracy\n",
    "- Ablation will be required to reduce analysis time\n",
    "\n",
    "### Solution\n",
    "All of the above can be achieved with the help of a custom generator which generates data in batches as per requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7668b6d0-d43c-49f2-8bc0-8bef9c0b04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProps:\n",
    "    \"\"\"Image class to easily store, retrieve and update properties of input images during training\"\"\"\n",
    "    img_selection_via_idx = [3, 6, 9, 12, 15, 18, 21]\n",
    "    img_selection_len = len(img_selection_via_idx)\n",
    "    \n",
    "    img_resize_height = 100\n",
    "    img_resize_width = 100\n",
    "    \n",
    "    img_crop_width_lower_limit = 10\n",
    "    img_crop_width_upper_limit = 90\n",
    "    img_crop_height_lower_limit = 10\n",
    "    img_crop_height_upper_limit = 90\n",
    "    \n",
    "    img_height = 80\n",
    "    img_width = 80\n",
    "    \n",
    "    NUM_RGB_CHANNELS = 3\n",
    "    \n",
    "    def normalize_channel(self, input_channel, lower_percentile=5, upper_percentile=95):\n",
    "        \"\"\"To normalize input channel using percentile values\"\"\"\n",
    "        lower_percentile_val = np.percentile(input_channel, lower_percentile)\n",
    "        upper_percentile_val = np.percentile(input_channel, upper_percentile)\n",
    "        \n",
    "        numerator = input_channel-lower_percentile_val\n",
    "        denominator = upper_percentile_val-lower_percentile_val\n",
    "        \n",
    "        normalized_channel = numerator/denominator\n",
    "        \n",
    "        return normalized_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f463d38-35df-4276-b540-ebef9ab99bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_props = ImageProps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00bce96b-0115-41fb-b814-a6ca564d6b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9, 12, 15, 18, 21]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_props.img_selection_via_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5365ef4-b568-44c0-ae66-b9548f12cc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoBatchGenerator:\n",
    "    \"\"\"Generator class to generate images in batches as per requirement\n",
    "    \n",
    "    Number of channels in RGB image is 3\n",
    "    Number of gestures / output classes is 5\n",
    "    \n",
    "    Batch Data dimensions:\n",
    "    - images have 2 dimensions (width x height)\n",
    "    - rgb images have 3 channels (width x height x 3)\n",
    "    - videos are sequence of rgb images (sequence of images x width x height x 3)\n",
    "    - each batch has prespecified number of videos (batch size * sequence of images * width * height * 3)\n",
    "    \"\"\"\n",
    "    batch_size = 3\n",
    "    num_images_per_video = img_props.img_selection_len\n",
    "    img_height = img_props.img_height\n",
    "    img_width = img_props.img_width\n",
    "    NUM_RGB_CHANNELS = 3\n",
    "    NUM_CLASSES = 5\n",
    "    SHOW_IMAGE = False\n",
    "    \n",
    "    def __init__(self, batch_size=batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def batch_generator(self, parent_folder_path, df):\n",
    "        num_videos = len(df)\n",
    "        # batch size cannot be larger than the input video sequence\n",
    "        self.batch_size = min(self.batch_size, num_videos)\n",
    "        num_batches = num_videos//self.batch_size\n",
    "        extra_batch_size = num_videos%self.batch_size\n",
    "        \n",
    "        log.info(f\"Source Path: {parent_folder_path}\")\n",
    "        log.info(f\"Number of Videos: {num_videos}\")\n",
    "        log.info(f\"Batch Size: {self.batch_size}\") \n",
    "        log.info(f\"Number of Batches: {num_batches}\")\n",
    "        log.info(f\"Extra Batch Size (zero means no extra batch): {extra_batch_size}\")\n",
    "        \n",
    "        while True:\n",
    "            shuffled_df = shuffle(df, random_state=RANDOM_SEED)\n",
    "            shuffled_video_folders = shuffled_df['Video Folder']\n",
    "            shuffled_labels = shuffled_df['Label']\n",
    "            \n",
    "            log.debug(f\"{shuffled_df.head()}\")\n",
    "            \n",
    "            for batch_id in range(num_batches):\n",
    "                log.debug(f\"Current Batch: {batch_id}\")\n",
    "                batch_data = np.zeros((self.batch_size, \n",
    "                                       self.num_images_per_video, \n",
    "                                       self.img_width, self.img_height, \n",
    "                                       self.NUM_RGB_CHANNELS))\n",
    "                batch_labels = np.zeros((self.batch_size, \n",
    "                                         self.NUM_CLASSES))\n",
    "                \n",
    "                for video_id in range(self.batch_size):\n",
    "                    video_folder_id = video_id + batch_id*self.batch_size\n",
    "                    video_folder_path = os.path.join(parent_folder_path, shuffled_video_folders[video_folder_id])\n",
    "                    log.debug(f'id: {video_folder_id} video_folder_path: {video_folder_path}')\n",
    "                    imgs_in_video = os.listdir(video_folder_path)\n",
    "                    log.debug(f'first image: {imgs_in_video[0]}')\n",
    "                    \n",
    "                    for img_id, img_id_in_video in enumerate(img_props.img_selection_via_idx):\n",
    "                        img = imgs_in_video[img_id_in_video]\n",
    "                        log.debug(f'current image via selection: {img}')\n",
    "                        img_path = os.path.join(video_folder_path, img)\n",
    "                        log.debug(f'current image via selection [path]: {img_path}')\n",
    "                        img_array = imread(img_path).astype(np.float32)\n",
    "                        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        resized_image = cv2.resize(img_array, (\n",
    "                                        img_props.img_resize_width, \n",
    "                                        img_props.img_resize_height,\n",
    "                                        ))\n",
    "                        \n",
    "                        cropped_image = resized_image = resized_image[\n",
    "                            img_props.img_crop_width_lower_limit:img_props.img_crop_width_upper_limit,\n",
    "                            img_props.img_crop_height_lower_limit:img_props.img_crop_height_upper_limit,\n",
    "                        ]\n",
    "                        \n",
    "                        log.debug(f\"Shape of cropped image (after resize): {cropped_image.shape}\")\n",
    "                        \n",
    "                        red_channel = cropped_image[:, :, 0]\n",
    "                        green_channel = cropped_image[:, :, 1]\n",
    "                        blue_channel = cropped_image[:, :, 2]\n",
    "                        \n",
    "                        batch_data[video_id, img_id, :, :, 0] = img_props.normalize_channel(red_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 1] = img_props.normalize_channel(green_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 2] = img_props.normalize_channel(blue_channel)\n",
    "                        \n",
    "                        if self.SHOW_IMAGE:\n",
    "                            plt.imshow(batch_data[video_id, img_id, :, :, :])\n",
    "                            plt.show()\n",
    "                        \n",
    "                    batch_labels[video_id, shuffled_labels[video_folder_id]] = 1\n",
    "                    log.debug(f\"batch data: for video:img [{video_id}:{img_id}] = {batch_data[video_id, img_id, :, :, 0]}\")\n",
    "                    log.debug(f\"batch label: {video_id} = {batch_labels[video_id]}\")\n",
    "                yield batch_data, batch_labels\n",
    "            \n",
    "            if extra_batch_size:\n",
    "                last_batch_id = batch_id + 1\n",
    "                log.debug(f\"Current Batch (Extra Batch): {last_batch_id}\")\n",
    "                batch_data = np.zeros((extra_batch_size, \n",
    "                                       self.num_images_per_video, \n",
    "                                       self.img_width, self.img_height, \n",
    "                                       self.NUM_RGB_CHANNELS))\n",
    "                batch_labels = np.zeros((extra_batch_size, \n",
    "                                         self.NUM_CLASSES))\n",
    "                \n",
    "                for video_id in range(extra_batch_size):\n",
    "                    video_folder_id = video_id + last_batch_id*self.batch_size\n",
    "                    video_folder_path = os.path.join(parent_folder_path, shuffled_video_folders[video_folder_id])\n",
    "                    log.debug(f'id: {video_folder_id} video_folder_path: {video_folder_path}')\n",
    "                    imgs_in_video = os.listdir(video_folder_path)\n",
    "                    log.debug(f'first image: {imgs_in_video[0]}')\n",
    "                    \n",
    "                    for img_id, img_id_in_video in enumerate(img_props.img_selection_via_idx):\n",
    "                        img = imgs_in_video[img_id_in_video]\n",
    "                        log.debug(f'current image via selection: {img}')\n",
    "                        img_path = os.path.join(video_folder_path, img)\n",
    "                        log.debug(f'current image via selection [path]: {img_path}')\n",
    "                        img_array = imread(img_path).astype(np.float32)\n",
    "                        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        resized_image = cv2.resize(img_array, (\n",
    "                                        img_props.img_resize_width, \n",
    "                                        img_props.img_resize_height,\n",
    "                                        ))\n",
    "                        \n",
    "                        cropped_image = resized_image[\n",
    "                            img_props.img_crop_width_lower_limit:img_props.img_crop_width_upper_limit,\n",
    "                            img_props.img_crop_height_lower_limit:img_props.img_crop_height_upper_limit,\n",
    "                        ]\n",
    "                        \n",
    "                        log.debug(f\"Shape of cropped image (after resize): {cropped_image.shape}\")\n",
    "                        \n",
    "                        red_channel = cropped_image[:, :, 0]\n",
    "                        green_channel = cropped_image[:, :, 1]\n",
    "                        blue_channel = cropped_image[:, :, 2]\n",
    "                        \n",
    "                        batch_data[video_id, img_id, :, :, 0] = img_props.normalize_channel(red_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 1] = img_props.normalize_channel(green_channel)\n",
    "                        batch_data[video_id, img_id, :, :, 2] = img_props.normalize_channel(blue_channel)\n",
    "                        \n",
    "                        if self.SHOW_IMAGE:\n",
    "                            plt.imshow(batch_data[video_id, img_id, :, :, :])\n",
    "                            plt.show()\n",
    "                            \n",
    "                    batch_labels[video_id, shuffled_labels[video_folder_id]] = 1\n",
    "                    log.debug(f\"batch data: for video:img [{video_id}:{img_id}] = {batch_data[video_id, img_id, :, :, 0]}\")\n",
    "                    log.debug(f\"batch label: {video_id} = {batch_labels[video_id]}\")\n",
    "                yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b53b1-5f2d-40fc-9453-3239a4e02fe7",
   "metadata": {},
   "source": [
    "## Sanity Check for Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81d1b162-8eb9-4150-9455-9628504309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = VideoBatchGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35250a29-cd71-4be3-ab4b-3528ffe8ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1520108a-e5a5-4b48-b882-3b003c837488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c165efe9-f062-4a48-a995-9480df004e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = v.batch_generator(train_folder, train_df[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a00e816-ee14-4623-bef9-22c86d655c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "155a6bcb-f0d1-4265-865a-2ab2c81b60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.SHOW_IMAGE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a0cef85-a3c7-41e5-a28f-f1088ae6a848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "526764ac-760a-4a9c-90f9-624cbd74ef28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d47a308-8a31-43dd-b3fd-741cd2965568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66c60da1-6c4f-4809-94d9-dafdc9542cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d8c2539-d2bf-4a08-a656-a3e010aea75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8fd7d53-9641-48e1-a769-43621f3c83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = v.batch_generator(val_folder, val_df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a39c3e05-4802-4bab-8715-0a9b6fb9c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v.batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b928c003-f1ab-4b72-a892-37cbe18ede01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e7130c1-5dae-49e0-a66b-9c2cf5792748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da96ca8e-4548-407a-b693-e7ed39ae9d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = next(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2e9ecc7-664d-4c8d-b0d0-2e2d5cfea965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = next(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306583e5-f228-4245-b99e-38a1d321de35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2aefd835-3fdf-4468-96a5-c552a3cb53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelProps:\n",
    "    \"\"\"Properties that logically belong to a Model will be kept here\"\"\"\n",
    "    current_date_time = str(datetime.datetime.now()).replace(' ', '').replace(':', '_')\n",
    "    num_epochs = 3\n",
    "    model_init_name = 'model_init'\n",
    "    model_root_folder = \"models\"\n",
    "    num_train_videos = None\n",
    "    num_val_videos = None\n",
    "    steps_per_epoch_train = None\n",
    "    steps_per_epoch_val = None\n",
    "    NUM_CLASSES = 5\n",
    "    sample_shape = (img_props.img_selection_len, \n",
    "                    img_props.img_width, img_props.img_height, \n",
    "                    img_props.NUM_RGB_CHANNELS)\n",
    "    \n",
    "    def __init__(self, train_df, val_df, batch_size):\n",
    "        self.num_train_videos = len(train_df)\n",
    "        self.num_val_videos = len(val_df)\n",
    "        self.model_folder_name = self.model_init_name + \"_\" + self.current_date_time + \"/\"\n",
    "        self.model_folder_path = os.path.join(self.model_root_folder, self.model_folder_name)\n",
    "        \n",
    "        log.info(f\"Number of Training Videos: {self.num_train_videos}\")\n",
    "        log.info(f\"Number of Validation Videos: {self.num_val_videos}\")\n",
    "        \n",
    "        self.steps_per_epoch_train = self.calculate_steps_per_epoch(self.num_train_videos, batch_size)\n",
    "        self.steps_per_epoch_val = self.calculate_steps_per_epoch(self.num_val_videos, batch_size)\n",
    "        \n",
    "        log.info(f\"Number of Steps (Train): {self.steps_per_epoch_train}\")\n",
    "        log.info(f\"Number of Steps (Val): {self.steps_per_epoch_val}\")\n",
    "        \n",
    "        log.info(f\"Sample Shape: {self.sample_shape}\")\n",
    "        \n",
    "        if not os.path.exists(self.model_root_folder):\n",
    "            os.mkdir(self.model_root_folder)\n",
    "        \n",
    "        if not os.path.exists(self.model_folder_path):\n",
    "            os.mkdir(self.model_folder_path)\n",
    "        \n",
    "    def calculate_steps_per_epoch(self, num_videos, batch_size):\n",
    "        \"\"\"Calculates steps per epoch based on the input videos and batch size\"\"\"\n",
    "        steps_per_epoch = (num_videos//batch_size)+1 if num_videos%batch_size else num_videos/batch_size\n",
    "        return steps_per_epoch\n",
    "        \n",
    "    def model_config(self):\n",
    "        model_file_path = os.path.join(self.model_folder_path, \n",
    "            'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "        )\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(\n",
    "            model_file_path, \n",
    "            monitor='val_loss',\n",
    "            verbose=1,\n",
    "            save_best_only=False, \n",
    "            save_weights_only=False, \n",
    "            mode='auto', \n",
    "            save_freq='epoch'\n",
    "        )\n",
    "\n",
    "        LR = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.1,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            min_delta=0.0001,\n",
    "            cooldown=0,\n",
    "            min_lr=0,\n",
    "        )\n",
    "        \n",
    "        callbacks_list = [LR, checkpoint]\n",
    "        \n",
    "        return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff90f798-82ca-4366-9fcb-8c9a6b61f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = ModelProps(train_df, val_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60e56e-bb29-4ee4-a142-6d8b2ef5f235",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17eaec23-ec87-4f5b-b727-ca01ed482992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class ModelBuilder(ModelProps, VideoBatchGenerator):\n",
    "    def __init__(self, train_df, val_df, batch_size):\n",
    "        super().__init__(train_df, val_df, batch_size)\n",
    "        video_batch_generator = VideoBatchGenerator(batch_size=batch_size)\n",
    "        self.train_generator = video_batch_generator.batch_generator(train_folder, train_df)\n",
    "        self.val_generator = video_batch_generator.batch_generator(val_folder, val_df)\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def model_builder(self):\n",
    "        \"\"\"Building model based on Keras API\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=self.sample_shape, padding='same'))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.NUM_CLASSES, activation='softmax'))\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def model_compiler(self, optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy']):\n",
    "        \"\"\"Compiling model by taking in optimizer, loss, and metrics\"\"\"\n",
    "        model = self.model_builder()\n",
    "        model.compile(optimizer, loss, metrics)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bfe69d4-f6c2-40a8-add8-72267f97dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, model_builder, model):\n",
    "        self.model_builder = model_builder\n",
    "        self.model = model\n",
    "        \n",
    "    def model_training(self):\n",
    "        self.history = self.model.fit(\n",
    "            self.model_builder.train_generator, \n",
    "            steps_per_epoch=self.model_builder.steps_per_epoch_train, \n",
    "            epochs=self.model_builder.num_epochs, \n",
    "            callbacks=self.model_builder.model_config(), \n",
    "            validation_data=self.model_builder.val_generator, \n",
    "            validation_steps=self.model_builder.steps_per_epoch_val, \n",
    "            class_weight=None, \n",
    "            workers=1, \n",
    "            initial_epoch=0)\n",
    "        \n",
    "    def model_analysis(self):\n",
    "        acc = self.history.history['categorical_accuracy']\n",
    "        val_acc = self.history.history['val_categorical_accuracy']\n",
    "\n",
    "        loss = self.history.history['loss']\n",
    "        val_loss = self.history.history['val_loss']\n",
    "\n",
    "        epochs_range = range(self.model_builder.num_epochs)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, loss, label='Training Loss')\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e921d-6305-4710-901d-d9d2eee86cdf",
   "metadata": {},
   "source": [
    "## CNN3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cf983a6-fad4-4054-b516-17b6fce2079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Videos: 12\n",
      "Number of Validation Videos: 12\n",
      "Number of Steps (Train): 4.0\n",
      "Number of Steps (Val): 4.0\n",
      "Sample Shape: (7, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "model_builder = ModelBuilder(train_df[0:12], val_df[0:12], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "827dd4e5-e97f-46c6-ad30-655340f1b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_1 = model_builder.model_compiler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "342ac998-548f-4b15-9531-bebed9bf924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 7, 80, 80, 16)     1312      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 80, 80, 16)    64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 7, 80, 80, 32)     13856     \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 3, 40, 40, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3, 40, 40, 32)    128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 3, 40, 40, 64)     55360     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3, 40, 40, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 307200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               39321728  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,393,349\n",
      "Trainable params: 39,393,125\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17b437e6-a415-42c4-ad91-ca986aa6ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_simple_model_1 = ModelTraining(model_builder, simple_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ba03163-734a-43fd-9238-2fd5723f41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_simple_model_1.model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c66af101-2b8b-4d1e-a44d-2178bb4ca159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MB(ModelBuilder):\n",
    "    \n",
    "    def model_builder(self):\n",
    "        \"\"\"Building model based on Keras API\"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=self.sample_shape, padding='same'))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(BatchNormalization(center=True, scale=True))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.NUM_CLASSES, activation='softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb79dd11-fdb6-41cb-bf36-2b8dfc4126cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Videos: 663\n",
      "Number of Validation Videos: 100\n",
      "Number of Steps (Train): 4\n",
      "Number of Steps (Val): 1\n",
      "Sample Shape: (7, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "mm = MB(train_df, val_df, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd972d88-519d-4859-8b3b-9485a2972582",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = mm.model_compiler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ef8d267-3281-417f-a229-d9ce281d5394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_3 (Conv3D)           (None, 7, 80, 80, 16)     1312      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 7, 80, 80, 16)    64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 7, 80, 80, 32)     13856     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 3, 40, 40, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 3, 40, 40, 32)    128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 3, 40, 40, 64)     55360     \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 1, 20, 20, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1, 20, 20, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3276928   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,382,213\n",
      "Trainable params: 3,381,989\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "576b4b6e-3ed6-4b36-952b-017cbfd5b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmt = ModelTraining(mm, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fccf4bf3-ab2d-4a0a-b628-9907540548b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmt.model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15544a-9ce8-437c-a52f-295d0c7f15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmt.model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f48080-1a83-47fc-90ef-673f1c97d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_simple_model_1.model_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8c0a1-970e-43a6-abba-015c5e3837e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c86a34a-fc80-4216-95cc-22aa571578c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Videos: 663\n",
      "Number of Validation Videos: 100\n",
      "Number of Steps (Train): 3\n",
      "Number of Steps (Val): 1\n",
      "Sample Shape: (7, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "model_builder = ModelBuilder(train_df, val_df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9cd2500-4bdb-41a9-9778-5d61a880ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48b5e900-efb4-4f60-8834-6552d31c7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_2 = model_builder.model_compiler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7aae8a7-dd05-47ea-ba52-3cbf56e36a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_simple_model_on_large_data = ModelTraining(model_builder, simple_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b259b6bb-fbca-40ec-a333-2d553ec8b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path: Project_data\\train\n",
      "Number of Videos: 663\n",
      "Batch Size: 300\n",
      "Number of Batches: 2\n",
      "Extra Batch Size (zero means no extra batch): 63\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 89.4317 - categorical_accuracy: 0.1916  Source Path: Project_data\\val\n",
      "Number of Videos: 100\n",
      "Batch Size: 100\n",
      "Number of Batches: 1\n",
      "Extra Batch Size (zero means no extra batch): 0\n",
      "\n",
      "Epoch 00001: saving model to models\\model_init_2022-01-0216_41_25.590440\\model-00001-89.43166-0.19155-153.47650-0.30000.h5\n",
      "3/3 [==============================] - 176s 43s/step - loss: 89.4317 - categorical_accuracy: 0.1916 - val_loss: 153.4765 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 20.5491 - categorical_accuracy: 0.5659 \n",
      "Epoch 00002: saving model to models\\model_init_2022-01-0216_41_25.590440\\model-00002-20.54911-0.56587-227.84879-0.24000.h5\n",
      "3/3 [==============================] - 106s 21s/step - loss: 20.5491 - categorical_accuracy: 0.5659 - val_loss: 227.8488 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.0360 - categorical_accuracy: 0.8327 \n",
      "Epoch 00003: saving model to models\\model_init_2022-01-0216_41_25.590440\\model-00003-4.03598-0.83270-233.60809-0.24000.h5\n",
      "3/3 [==============================] - 62s 21s/step - loss: 4.0360 - categorical_accuracy: 0.8327 - val_loss: 233.6081 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "training_simple_model_on_large_data.model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d39a82e-7756-4806-b2b3-a0f44bc1b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_simple_model_on_large_data.model_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641eb239-445b-4f68-83a6-22f9a377b98f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11f943-6d12-4efe-9319-8c88984bc8d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN + RNN combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb2c44ff-3fa2-4f7a-a45b-56984d2a0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c46f382b-5093-4a45-83e7-2560ec9a87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(img_props.img_width,img_props.img_height,img_props.NUM_RGB_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dff70b4-f57c-4670-978e-c85fdf99950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(ModelBuilder):\n",
    "    \n",
    "    def model_builder(self):\n",
    "        cnn = Sequential([resnet])\n",
    "        cnn.add(Conv2D(64,(2,2),strides=(1,1),padding='same'))\n",
    "        cnn.add(Conv2D(16,(3,3),strides=(1,1)))\n",
    "        cnn.add(Flatten())\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(cnn,input_shape=(None, img_props.img_width,img_props.img_height,img_props.NUM_RGB_CHANNELS)))\n",
    "        model.add(GRU(16,input_shape=(None,30,256),return_sequences=True))\n",
    "        model.add(GRU(8))\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d8885e5-9c41-40b4-b60e-0969a361d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Videos: 663\n",
      "Number of Validation Videos: 100\n",
      "Number of Steps (Train): 67\n",
      "Number of Steps (Val): 10.0\n",
      "Sample Shape: (7, 80, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(train_df, val_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "835d43e4-fb08-435d-aa67-417c8b751867",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = rnn.model_compiler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a895696-bc2a-46d8-a9bc-82497409f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training = ModelTraining(rnn, rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1f418-3e4e-4fec-8389-32313c4e05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path: Project_data\\train\n",
      "Number of Videos: 663\n",
      "Batch Size: 10\n",
      "Number of Batches: 66\n",
      "Extra Batch Size (zero means no extra batch): 3\n",
      "Epoch 1/3\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4673 - categorical_accuracy: 0.3650Source Path: Project_data\\val\n",
      "Number of Videos: 100\n",
      "Batch Size: 10\n",
      "Number of Batches: 10\n",
      "Extra Batch Size (zero means no extra batch): 0\n"
     ]
    }
   ],
   "source": [
    "rnn_training.model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea2411-4bec-4439-9000-7e92a5a34412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
